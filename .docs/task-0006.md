# Task 0006: Build activity ingestion pipeline

## Phase
Phase 2: Core Processing (Weeks 3-4)

## Description
Implement the complete pipeline for ingesting engineer activities, from API endpoint to database storage and job queuing.

## Acceptance Criteria (status)
- [x] Implement `POST /v1/activities` endpoint — Done (`api/activities.go`)
- [x] Add request validation for activity submissions — Done (basic validation: required fields, length)
- [x] Store activities in `raw_activities` table — Done (SQLite repo `CreateActivity`)
- [x] Queue background processing jobs — Done (job row created after activity insert; `processing_jobs`)
- [x] Implement activity history endpoint (`GET /v1/activities`) — Done (`api/activities.go`)
- [x] Add pagination support for activity lists — Done (limit + offset, repo and handler)
- [x] Implement proper error responses and status codes — Done (400 for validation, 201 for creation, 500 for server errors)
- [~] Add activity deduplication logic — Partial (left as TODO; simple deduplication not implemented)

## Dependencies
- Task 0003 (API server) — used existing middleware and route wiring
- Task 0005 (Data models and repositories) — repository interfaces and SQLite implementation extended

## Effort
3-4 days (implemented incrementally across handlers, repo, and tests)

## Technical Notes / Implementation Summary
- Validation: `api/activities.go` validates required `engineer_id` and `activity` fields and enforces a max length (2,000 chars). Optional `timestamp` field is accepted but not used to override the created timestamp in the DB yet.
- Storage: Activities are stored in `raw_activities` via `CreateActivity` in `internal/repository/sqlite/sqlite_repo.go`.
- Jobs: After storing an activity, a processing job row is created in `processing_jobs` (`CreateJob`). Job enqueue failures are logged but do not fail the API request.
- Pagination: The repository API was extended to support offset-based pagination: `ListByEngineer(ctx, engineerID, limit, offset)` and `CountActivitiesByEngineer(ctx, engineerID)` to supply total-count metadata. The handler returns JSON with `total`, `limit`, `offset`, and `items`.
- Error handling: Handlers return appropriate HTTP status codes and JSON content-type headers.
- Deduplication: Not implemented; left as a TODO. Reasonable approaches: short-time-window hashing, database uniqueness constraints, or a de-dupe worker.

## Files changed / created
- api/activities.go — new handler for create & list (returns pagination metadata)
- api/activities_test.go — tests for creation and offset-based pagination
- pkg/repository/repository.go — extended `ActivityRepo` interface (limit+offset and Count)
- internal/repository/sqlite/sqlite_repo.go — implemented LIMIT/OFFSET query and Count method
- internal/repository/sqlite/sqlite_test.go — updated tests to assert offset semantics

## How to run tests (local)
Run the new API and repo tests:

```bash
cd /g/code/Go/garnizeh/rag
go test ./api -v
go test ./internal/repository/sqlite -v
```

## Next steps / Recommendations
- Implement deduplication strategy (worker or DB constraint) — TODO
- Derive `engineer_id` from authenticated JWT claims instead of requiring it in the payload (improves security and UX)
- Add pagination metadata such as `total_pages` or `next`/`prev` links
- Add more validation and sanitization for activity text (strip dangerous content)
- Add integration tests that exercise the full pipeline (HTTP -> DB -> job processing)

## Definition of Done (re-validated)
- Activity submission endpoint is functional — Done
- Activities are properly stored in database — Done
- Background processing jobs are queued — Done (row created)
- Activity history can be retrieved with pagination and total count — Done
- Error handling is comprehensive for implemented cases — Done
- API follows documented specification (with noted TODOs) — Done (except deduplication)
